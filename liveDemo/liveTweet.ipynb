{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Importing Libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from config import *\n",
    "import time\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver startup\n",
    "The following code will go to twitter and accept the cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 5 seconds\n",
      "Done Waiting\n"
     ]
    }
   ],
   "source": [
    "#get twitter.com\n",
    "driver.get(\"https://twitter.com/\") #driver.get returns after the page is loaded but just to be sure, I'll wait 5 more seconds\n",
    "print(\"Waiting for 5 seconds\")\n",
    "time.sleep(5)\n",
    "print(\"Done Waiting\")\n",
    "#click on the full xpath to accept cookies\n",
    "driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div/div[2]/div[1]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture all the elements whose tag is 'article'\n",
    "def getTweets(tagName = 'article'):\n",
    "    tweets = driver.find_elements(By.TAG_NAME, tagName)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetContent(tweet):\n",
    "    return \" \".join(tweet.text.split('\\n')[4:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printCurrentTweets(tweets = []):\n",
    "    \"\"\"\n",
    "    This function prints the current tweets on the page that can be located through the tag name 'article'\n",
    "    \"\"\"\n",
    "    tweets = tweets if len(tweets) > 0 else getTweets()\n",
    "    for tweet in tweets:\n",
    "        body = getTweetContent(tweet)\n",
    "        print(body)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorBackground(tweet, color = \"red\"):\n",
    "    \n",
    "    driver.execute_script(\"arguments[0].style.backgroundColor = '\"+color+\"';\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = getTweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campedelli: “Un tifoso su tre è bianconero: non mi pare il caso di rinunciare a una società così importante. L'ha detto anche Gravina, che bisogna tutelare il brand Juve. Di fatto, la Juve se la caverà con una piccola multa: direi risibile rispetto alle casse societarie. Ne…\n",
      "--------------------------------------------------\n",
      "Con il patteggiamento di ieri si chiude una delle pagine più irrazionali della giustizia sportiva italiana. La  @juventusfc  viene penalizzata per 10 punti sul \"caso plusvalenze fittizie\" e non ne è stata provata una. La sanzione deriva dalla violazione della lealtà sportiva  1/7 119\n",
      "--------------------------------------------------\n",
      "Oggi Finale di #EuropaLeague: #SivigliaRoma  7/6 Finale di #ConferenceLeague: #FiorentinaWestHam  10/6 Finale di #ChampionsLeague #CityInter  Da ZERO a TRE quante ne portiamo a casa?\n",
      "--------------------------------------------------\n",
      "Se sei l'Inter patteggi 100mln di plusvalenze fittizie con 90mila € e ti salvi dalla B x Recoba e prescrizione, se sei la Juve ti danno 10 punti e tolgono 70mln x la CL Ma l'interista evoluto non sa che Chievo prese 3 punti ed è andato in D perché è fallito e continua a ragliare Cita Tweet Interisti Stalinisti @IStalinisti · 30 mag Dunque se sei il #ChievoVerona vai in serie D, se sei la #juventus detti le condizioni per il #patteggiamento e resti in Serie A. Ma secondo i trogloditi juventini dell’internet, FIGC e Procura sono contro di loro: vorrei un decimo della loro incapacità di discernimento.\n",
      "--------------------------------------------------\n",
      "#Bandecchi scatenato: 'La #Juventus ha rubato, è meglio che Gravina cambi spacciatore' http://dlvr.it/SptYbz\n",
      "--------------------------------------------------\n",
      "\"Sarebbe un giorno triste per il calcio. La strada più semplice per la Juve è rinnegare la Superlega. Non è che l’Uefa aumenterà le sanzioni perché la Juve è una ribelle. Ma si può presumere che aiuterà in tutti i modi possibili un club “figliol prodigo”.\"  Neanche nelle parodie. Cita Tweet La Gazzetta dello Sport @Gazzetta_it · 19h #Juve, non è finita: linea dura Uefa, il club rischia un anno di stop http://rosea.it/be6eeaddpT\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printCurrentTweets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow  as  tf\n",
    "from  tensorflow  import  keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot  as  plt\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import pickle5 as pickle\n",
    "\n",
    "import pandas  as  pd\n",
    "import tqdm as tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "#import  the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the ./disasterModel.h5 model using keras\n",
    "model = keras.models.load_model('./models/disasterModel.h5', compile=False)\n",
    "#compile the model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "#load the tokenizer using pickle\n",
    "with open('./models/tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hazem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleanup\n",
    "\n",
    "This function takes a raw text string and applies a standard NLP preprocessing pipeline consisting of the following steps:\n",
    "- Text cleaning\n",
    "- Tokenization\n",
    "- Stopwords removal\n",
    "- Stemming (Snowball stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Text cleaning pipeline\n",
    "    \n",
    "    # 1. Text cleaning\n",
    "    # 1.a Case normalization\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 1.b Trimming\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 1.c Filter out punctuation symbols\n",
    "    text = re.sub(\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # 1.d Filter out any internal extra whitespace\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    \n",
    "    # 2. Tokenization (split text into tokens)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # 3. Stopwords removal\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    terms = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # 4. Stemming (Snowball stemmer)\n",
    "    stemmer = SnowballStemmer(language=\"english\")\n",
    "    terms_stemmed = [stemmer.stem(term) for term in terms]\n",
    "    \n",
    "    # Return the cleaned text\n",
    "    return \" \".join(terms_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareText(rawTweet):\n",
    "    \"\"\"\n",
    "    This function takes a raw tweet and returns a list of cleaned tokens\n",
    "    \"\"\"\n",
    "    #clean the raw tweet\n",
    "    cleanTweet = clean_text(getTweetContent(rawTweet))\n",
    "    #tokenize the clean tweet\n",
    "    tokens = tokenizer.texts_to_sequences([cleanTweet])\n",
    "    #pad the tokens\n",
    "    paddedTokens = pad_sequences(tokens, maxlen=23, padding='post')\n",
    "    return paddedTokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to change the tweet background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLive():\n",
    "    tweets = getTweets()\n",
    "    for tweet in tweets:\n",
    "        prediction = np.round(model.predict(prepareText(tweet))[0]) #1 disaster, 0 not disaster\n",
    "        if prediction == 1:\n",
    "            colorBackground(tweet, \"red\")\n",
    "        else:\n",
    "            colorBackground(tweet, \"green\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Handling\n",
    "\n",
    "Now we need a way to let the user interact with the predictor. \n",
    "Whenever the user presses ENTER, the application will fetch the tweets nearby and will classify them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "from pynput import keyboard\n",
    "\n",
    "# Define the code to be executed when the key is pressed\n",
    "def handle_key_press(key):\n",
    "    if key == keyboard.Key.enter:\n",
    "        print(\"Enter key pressed!\")\n",
    "        #prevent the user from scrolling down\n",
    "        predictLive()\n",
    "\n",
    "\n",
    "    elif key == keyboard.Key.esc:\n",
    "        print(\"Escape key pressed!\")\n",
    "        # Stop listener\n",
    "        return False\n",
    "    elif key == keyboard.Key.shift_r:\n",
    "        #take a screenshot\n",
    "        #get time stamp \n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        driver.save_screenshot(f\"./screenshots/{timestamp}.png\")\n",
    "        print(\"Screenshot taken!\")\n",
    "    \n",
    "\n",
    "# Create a listener for key press events\n",
    "listener = keyboard.Listener(on_press=handle_key_press)\n",
    "\n",
    "# Start the listener\n",
    "listener.start()\n",
    "\n",
    "# Keep the program running until a specific key is pressed (e.g., Escape)\n",
    "listener.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
