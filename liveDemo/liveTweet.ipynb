{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Importing Libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from config import *\n",
    "import time\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver startup\n",
    "The following code will go to twitter and accept the cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 5 seconds\n",
      "Done Waiting\n"
     ]
    }
   ],
   "source": [
    "#get twitter.com\n",
    "driver.get(\"https://twitter.com/\") #driver.get returns after the page is loaded but just to be sure, I'll wait 5 more seconds\n",
    "print(\"Waiting for 5 seconds\")\n",
    "time.sleep(5)\n",
    "print(\"Done Waiting\")\n",
    "#click on the full xpath to accept cookies\n",
    "driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div/div[2]/div[1]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture all the elements whose tag is 'article'\n",
    "def getTweets(tagName = 'article'):\n",
    "    tweets = driver.find_elements(By.TAG_NAME, tagName)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetContent(tweet):\n",
    "    return \" \".join(tweet.text.split('\\n')[4:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printCurrentTweets(tweets = []):\n",
    "    \"\"\"\n",
    "    This function prints the current tweets on the page that can be located through the tag name 'article'\n",
    "    \"\"\"\n",
    "    tweets = tweets if len(tweets) > 0 else getTweets()\n",
    "    for tweet in tweets:\n",
    "        body = getTweetContent(tweet)\n",
    "        print(body)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorBackground(tweet, color = \"red\"):\n",
    "    \n",
    "    driver.execute_script(\"arguments[0].style.backgroundColor = '\"+color+\"';\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = getTweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truly an iconic moment for the girls. #FRIENDS 1:04\n",
      "--------------------------------------------------\n",
      "German Shepherd babysitting the Dobermans\n",
      "--------------------------------------------------\n",
      "Cat bus\n",
      "--------------------------------------------------\n",
      "Incredible moment captured on video as a shark takes an injured sea turtle to humans on a boat so they can help save it  From  Alvin Foo\n",
      "--------------------------------------------------\n",
      "we went to a new park today. and right at the entrance. was a big bucket of tennis balls with a little sign. that the human said was there in memory of a very good dog. who really liked tennis balls. and that i could play with one. to help that very good dog be remembered\n",
      "--------------------------------------------------\n",
      "did he just lay an egg\n",
      "--------------------------------------------------\n",
      "A small reminder that people only fear sharks when dolphins are worse. You are more likely to get sexually assaulted by a dolphin than a shark. They torture other fish for fun, rаpe in packs and use puffer fish to get high Daily Loud @DailyLoud · 7h Incredible moment captured on video as a shark takes an injured sea turtle to humans on a boat so they can help save it  669\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "printCurrentTweets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 00:45:35.238132: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-31 00:45:35.258653: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-31 00:45:35.361414: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-31 00:45:35.362042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 00:45:36.097510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-31 00:45:40.389560: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow  as  tf\n",
    "from  tensorflow  import  keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot  as  plt\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import pickle5 as pickle\n",
    "\n",
    "import pandas  as  pd\n",
    "import tqdm as tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "#import  the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the ./disasterModel.h5 model using keras\n",
    "model = keras.models.load_model('./models/disasterModel.h5')\n",
    "#load the tokenizer using pickle\n",
    "with open('./models/tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shadow2030/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleanup\n",
    "\n",
    "This function takes a raw text string and applies a standard NLP preprocessing pipeline consisting of the following steps:\n",
    "- Text cleaning\n",
    "- Tokenization\n",
    "- Stopwords removal\n",
    "- Stemming (Snowball stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Text cleaning pipeline\n",
    "    \n",
    "    # 1. Text cleaning\n",
    "    # 1.a Case normalization\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 1.b Trimming\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 1.c Filter out punctuation symbols\n",
    "    text = re.sub(\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # 1.d Filter out any internal extra whitespace\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    \n",
    "    # 2. Tokenization (split text into tokens)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # 3. Stopwords removal\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    terms = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # 4. Stemming (Snowball stemmer)\n",
    "    stemmer = SnowballStemmer(language=\"english\")\n",
    "    terms_stemmed = [stemmer.stem(term) for term in terms]\n",
    "    \n",
    "    # Return the cleaned text\n",
    "    return \" \".join(terms_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareText(rawTweet):\n",
    "    \"\"\"\n",
    "    This function takes a raw tweet and returns a list of cleaned tokens\n",
    "    \"\"\"\n",
    "    #clean the raw tweet\n",
    "    cleanTweet = clean_text(getTweetContent(rawTweet))\n",
    "    #tokenize the clean tweet\n",
    "    tokens = tokenizer.texts_to_sequences([cleanTweet])\n",
    "    #pad the tokens\n",
    "    paddedTokens = pad_sequences(tokens, maxlen=23, padding='post')\n",
    "    return paddedTokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to change the tweet background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLive():\n",
    "    tweets = getTweets()\n",
    "    for tweet in tweets:\n",
    "        prediction = np.round(model.predict(prepareText(tweet))[0]) #1 disaster, 0 not disaster\n",
    "        if prediction == 1:\n",
    "            colorBackground(tweet, \"red\")\n",
    "        else:\n",
    "            colorBackground(tweet, \"green\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Handling\n",
    "\n",
    "Now we need a way to let the user interact with the predictor. \n",
    "Whenever the user presses ENTER, the application will fetch the tweets nearby and will classify them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Enter key pressed!\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Escape key pressed!\n"
     ]
    }
   ],
   "source": [
    "from pynput import keyboard\n",
    "\n",
    "# Define the code to be executed when the key is pressed\n",
    "def handle_key_press(key):\n",
    "    if key == keyboard.Key.enter:\n",
    "        print(\"Enter key pressed!\")\n",
    "        predictLive()\n",
    "\n",
    "    elif key == keyboard.Key.esc:\n",
    "        print(\"Escape key pressed!\")\n",
    "        # Stop listener\n",
    "        return False\n",
    "    elif key == keyboard.Key.shift_r:\n",
    "        #take a screenshot\n",
    "        #get time stamp \n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        driver.save_screenshot(f\"./screenshots/{timestamp}.png\")\n",
    "        print(\"Screenshot taken!\")\n",
    "    \n",
    "\n",
    "# Create a listener for key press events\n",
    "listener = keyboard.Listener(on_press=handle_key_press)\n",
    "\n",
    "# Start the listener\n",
    "listener.start()\n",
    "\n",
    "# Keep the program running until a specific key is pressed (e.g., Escape)\n",
    "listener.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
